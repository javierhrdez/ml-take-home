{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4r7WAozsHm9"
   },
   "source": [
    "# <img style=\"float: left; padding-right: 5px; width: 200px\" src=\"https://assets.entrepreneur.com/images/misc/1584487204_LOGOCODOS_fondoblanco-01.png?width=300\">\n",
    "#Data Science Interview\n",
    "\n",
    "## Take Home: New or Used\n",
    "\n",
    "\n",
    "### Julio 2023\n",
    "\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYw5R8X5sHm_"
   },
   "source": [
    "## Descripción\n",
    "\n",
    "El dataset otorgado tiene 100.000 registros de items extraidos del marketplace en MercadoLibre, caracterizados a través de 26 diferentes columnas.\n",
    "\n",
    "En el contexto del Marketplace de MercadoLibre, se detecta la necesidad de un algoritmo que prediga si un item listado en el marketplace es nuevo o usado.  \n",
    "La tarea consiste en diseñar un modelo de machine learning que prediga si un item es nuevo o usado, y evaluar el mismo sobre un conjunto de datos separado.  \n",
    "(Se adjunta una celda con la cual realizar la consumicion del dataset)\n",
    "\n",
    "Para ello sugerimos realizar en una primera instancia un Exploratory Data Analysis (EDA) de este dataset, para entender la información contenida y obtener insights relevantes para tareas analíticas.\n",
    "\n",
    "A continuación, una descripción de las columnas:\n",
    "\n",
    "| Variable | Descripción |\n",
    "| :------------- | :----------- |\n",
    "| id | ID de la publicación |\n",
    "| title | Título de la publicación |\n",
    "| date_created | Fecha de creación de la publicación |\n",
    "| base_price | Precio del producto en la publicación, sin descuento |\n",
    "| price | Precio del producto en la publicación, con descuento |\n",
    "| category_id | ID de categoría del producto |\n",
    "| tags | Tags de la publicación |\n",
    "| attributes | Atributos del producto publicado |\n",
    "| variations | Variaciones del producto publicado |\n",
    "| pictures | Fotos del producto publicado |\n",
    "| seller_id | ID del vendedor |\n",
    "| seller_country | País de residencia del vendedor |\n",
    "| seller_province | Provincia de residencia del vendedor |\n",
    "| seller_city | Ciudad de residencia del vendedor |\n",
    "| seller_loyalty | Loyalty o segmento del vendedor |\n",
    "| buying_mode | Modo de compra especificado |\n",
    "| shipping_mode | Modo de envío especificado |\n",
    "| shipping_admits_pickup | Flag indicando si se puede retirar al domicilio del vendedor |\n",
    "| shipping_is_free | Flag indicando si el envío es gratis |\n",
    "| status | Estado de la publicación |\n",
    "| sub_status | Sub-estado de la publicación |\n",
    "| warranty | Garantía del producto |\n",
    "| is_new | Flag indicando si el producto es nuevo |\n",
    "| initial_quantity | Stock inicial del producto |\n",
    "| sold_quantity | Stock vendido del producto |\n",
    "| available_quantity | Stock disponible del producto |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "# You can safely assume that `build_dataset` is correctly implemented\n",
    "def build_dataset():\n",
    "    data = [json.loads(x) for x in open(\"MLA_100k.jsonlines\")]\n",
    "    target = lambda x: x.get(\"condition\")\n",
    "    N = -10000\n",
    "    X_train = data[:N]\n",
    "    X_test = data[N:]\n",
    "    y_train = [target(x) for x in X_train]\n",
    "    y_test = [target(x) for x in X_test]\n",
    "    for x in X_test:\n",
    "        del x[\"condition\"]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTaJvdhLsHm_"
   },
   "source": [
    "## Tareas\n",
    "\n",
    "En este notebook se deberá cargar todas las librerías que se necesitan para explorar y procesar el dataset dado, y así realizar el modelo corresponendiente para resolver el objetivo propuesto. Se puede realizar cualquier análisis deseado, pero al final se espera encontrar realizadas las tareas del tipo \"requerido\". Además, hay algunos aspectos valorados del tipo \"deseable\" que podrían enriquecer el trabajo, y algunos \"bonus\" extra.\n",
    "\n",
    "El código debe ser desarrollado en Python 3.x (NO 2.x). Los reportes pueden estar en español o inglés.\n",
    "\n",
    "### Requerido\n",
    "\n",
    "- **Data QA:** Se debe chequear la calidad del dataset para hacer una evaluación de qué tan apropiados son los datos para tareas de Data Science. Proponga un conjunto de correcciones en los datos de ser necesario.\n",
    "- **Reporting:** Documente los resultados e insights obtenidos durante la exploración y describa conclusiones desde una perspectiva de negocio, soportado por gráficos / tablas / métricas.\n",
    "- **Feature Engineering:** Indicar y calcular posibles candidatos de features que podrían utilizarse en un modelo predictivo para resolver la tarea indicada, tanto desde las columnas originales como desde transformaciones.\n",
    "- **Machine Learning:** Realice un modelo predictivo capaz de solucionar la problematica descripta.\n",
    "- **Mostrar skills en Python:** Teniendo buenas practicas en la estructura del código y la documentación.\n",
    "- **Métricas:** Definir y calcular las métricas que considere más relevantes para la problemática propuesta.\n",
    "\n",
    "### Deseable\n",
    "\n",
    "- **Versionado de código con Git** (incluso puede publicarse en tu cuenta personal de GitHub!).\n",
    "- **Casos de uso:** Describir posibles casos de usos a tratar con este dataset que podrían agregar valor al negocio dado, indicando métodos / técnicas y algoritmos por cada uno de ellos, así como justificando las decisiones tomadas.\n",
    "\n",
    "### Bonus\n",
    "\n",
    "- Manejo de environment de desarrollo mediante alguna tecnología (e.g. Docker, virtualenv, conda).\n",
    "- Identificar nuevos atributos / tablas que podrían ser relevantes o necesarias para un mejor análisis.\n",
    "\n",
    "Este ejercicio está diseñado para ser completado en 4 - 6 hs siguiendo sólo los aspectos del tipo \"requerido\" y \"deseable\", pero se contempla una semana para entregarlo con todos los aspectos que se deseen completar.\n",
    "\n",
    "Una vez completado este ejercicio, por favor mandar un archivo ZIP de la carpeta con todos los recursos usados en este trabajo (e.g. Jupyter notebook, scripts, documentos, imágenes, etc), o bien el enlace al repositorio de GitHub, a santiago.feraud@mercadolibre.com.\n",
    "\n",
    "**Que te diviertas!**\n",
    "\n",
    "<img src=\"http://s3.amazonaws.com/melidata-external/data-science-interviews/2021/img/hunger_games_data_meme.jpeg\" alt=\"drawing\" style=\"width:200px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zjeLhCMKxNiy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "814db409262d41e59a8f535448fcae85",
   "lastKernelId": "3183b2f9-976f-49e9-9ea7-931bafbad9e4"
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
