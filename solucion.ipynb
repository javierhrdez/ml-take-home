{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef49b00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/javi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pprint\n",
    "from pymongo import MongoClient\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from stop_words import get_stop_words\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Descargar recursos necesarios de nltk\n",
    "nltk.download('punkt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "667d3a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"dataset/df_train.csv.gzip\", compression='gzip',  low_memory=False)\n",
    "df_test = pd.read_csv(\"dataset/df_test.csv.gzip\", compression='gzip',  low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8401f4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conn = MongoClient()\n",
    "#db = conn.ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8addb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_items = db.X_train\n",
    "#y_train_items = db.y_train\n",
    "#X_test_items = db.X_test\n",
    "#y_test_items = db.y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f360c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can safely assume that `build_dataset` is correctly implemented\n",
    "#def build_dataset():\n",
    "#    data = [json.loads(x) for x in open(\"MLA_100k.jsonlines\")]\n",
    "#    target = lambda x: x.get(\"condition\")\n",
    "#    N = -10000\n",
    "#    X_train = data[:N]\n",
    "#    X_test = data[N:]\n",
    "#    y_train = [target(x) for x in X_train]\n",
    "#    y_test = [target(x) for x in X_test]\n",
    "#    for x in X_test:\n",
    "#        del x[\"condition\"]\n",
    "#    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d9875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_raw, y_train_raw, X_test_raw, y_test_raw  = build_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802e096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_items.insert_many(X_train_raw)\n",
    "#X_test_items.insert_many(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31585049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_collect = X_train_items.find()\n",
    "#X_test_collect = X_test_items.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14cc40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = pd.DataFrame(X_train_collect)\n",
    "#X_test = pd.DataFrame(X_test_collect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b819108",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.pop(\"_id\")\n",
    "#X_test.pop(\"_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51921ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = pd.DataFrame({\"is_new\":y_train_raw})\n",
    "#y_test = pd.DataFrame({\"is_new\":y_test_raw})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678967df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train = pd.concat([X_train,y_train], axis = 1)\n",
    "#df_test = pd.concat([X_test,y_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d41f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"id\",\"title\",\"date_created\",\"base_price\",\"price\",\"category_id\",\"tags\",\"attributes\",\"variations\",\n",
    "           \"pictures\",\"seller_id\",\"seller_country\",\"seller_province\",\"seller_city\",\"seller_loyalty\",\"buying_mode\",\n",
    "           \"shipping_mode\",\"shipping_admits_pic\",\"shipping_is_free\",\"status\",\"sub_status\",\"warranty\",\n",
    "           \"is_new\",\"initial_quantity\",\"sold_quantity\",\"available_quantity\"] \n",
    "\n",
    "columns = [\"id\",\"title\",\"date_created\",\"base_price\",\"price\",\"category_id\",\"tags\",\"attributes\",\"variations\",\n",
    "           \"pictures\",\"seller_id\",\"seller_country\",\"seller_province\",\"seller_city\",\"buying_mode\",\n",
    "           \"shipping_mode\",\"shipping_admits_pic\",\"shipping_is_free\",\"status\",\"sub_status\",\"warranty\",\n",
    "           \"initial_quantity\",\"sold_quantity\",\"available_quantity\"] \n",
    "#columns = [\"date_created\",\"base_price\",\"price\",\"category_id\",\"tags\",\"attributes\",\"variations\",\n",
    "#           \"buying_mode\",\"status\",\"sub_status\",\"warranty\",\"initial_quantity\",\"sold_quantity\",\"available_quantity\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db2199f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 1 column 2 (char 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshipping\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/test/lib/python3.8/json/__init__.py:357\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    355\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    356\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/opt/anaconda3/envs/test/lib/python3.8/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/test/lib/python3.8/json/decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m \n\u001b[1;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)"
     ]
    }
   ],
   "source": [
    "json.loads(df_train[\"shipping\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eb3e4e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshipping_admits_pic\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshipping\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlocal_pick_up\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshipping_admits_pic\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshipping\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x : x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal_pick_up\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/test/lib/python3.8/site-packages/pandas-1.2.5-py3.8-macosx-10.9-x86_64.egg/pandas/core/series.py:4138\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4136\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4137\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 4138\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], Series):\n\u001b[1;32m   4141\u001b[0m     \u001b[38;5;66;03m# GH 25959 use pd.array instead of tolist\u001b[39;00m\n\u001b[1;32m   4142\u001b[0m     \u001b[38;5;66;03m# so extension arrays can be used\u001b[39;00m\n\u001b[1;32m   4143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_expanddim(pd_array(mapped), index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32mpandas/_libs/lib.pyx:2467\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshipping_admits_pic\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshipping\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x : \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal_pick_up\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      2\u001b[0m df_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshipping_admits_pic\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshipping\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x : x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal_pick_up\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "df_train[\"shipping_admits_pic\"] = df_train[\"shipping\"].apply(lambda x : x.get(\"local_pick_up\"))\n",
    "df_test[\"shipping_admits_pic\"] = df_test[\"shipping\"].apply(lambda x : x.get(\"local_pick_up\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ced5bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"shipping_admits_pic\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f806c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"shipping_mode\"] = X_train[\"shipping\"].apply(lambda x : x.get(\"mode\"))\n",
    "X_test[\"shipping_mode\"] = X_test[\"shipping\"].apply(lambda x : x.get(\"mode\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4caea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"shipping_mode\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17ad375",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"shipping_is_free\"] = X_train[\"shipping\"].apply(lambda x : x.get(\"free_shipping\"))\n",
    "X_test[\"shipping_is_free\"] = X_test[\"shipping\"].apply(lambda x : x.get(\"free_shipping\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e9172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"shipping_is_free\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dce058",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"seller_city\"] = X_train[\"seller_address\"].apply(lambda x : x.get(\"city\").get(\"name\") )\n",
    "X_test[\"seller_city\"] = X_test[\"seller_address\"].apply(lambda x : x.get(\"city\").get(\"name\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa255bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"seller_city\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eecc9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"seller_province\"] = X_train[\"seller_address\"].apply(lambda x : x.get(\"state\").get(\"name\") )\n",
    "X_test[\"seller_province\"] = X_test[\"seller_address\"].apply(lambda x : x.get(\"state\").get(\"name\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1fe4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"seller_province\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35647f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no se pide la ciudad en el dataset , pero creo que es relevante para tener contexto\n",
    "\n",
    "X_train[\"seller_country\"] = X_train[\"seller_address\"].apply(lambda x : x.get(\"country\").get(\"name\"))\n",
    "X_test[\"seller_country\"] = X_test[\"seller_address\"].apply(lambda x : x.get(\"country\").get(\"name\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf792d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"seller_country\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97da5b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[columns]\n",
    "X_test = X_test[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe406c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"title\"] = X_train[\"title\"].str.lower()\n",
    "X_train[\"warranty\"] = X_train[\"warranty\"].str.lower()\n",
    "\n",
    "X_test[\"title\"] = X_test[\"title\"].str.lower()\n",
    "X_test[\"warranty\"] = X_test[\"warranty\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0751216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"warranty\"] = np.where(X_train[\"warranty\"].notnull(), X_train[\"warranty\"], \"\")\n",
    "X_test[\"warranty\"] = np.where(X_test[\"warranty\"].notnull(), X_test[\"warranty\"], \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ddfe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[\"warranty\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf22c21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar las descripciones de los dos campos en un solo campo\n",
    "X_train['descripcion_combinada'] = X_train[\"title\"] + ' ' + X_train[\"warranty\"]\n",
    "X_test['descripcion_combinada'] = X_test[\"title\"] + ' ' + X_test[\"warranty\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325e555e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aa7a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"date_created\"] = pd.to_datetime(df_train[\"date_created\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8cab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"date_created\"].min(), df_train[\"date_created\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f595c684",
   "metadata": {},
   "outputs": [],
   "source": [
    "precio_prom_semanal = df_train.groupby([\"is_new\",pd.Grouper(key = 'date_created', freq = 'W')]).price.mean().fillna(0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de325d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "productos_nuevos = precio_prom_semanal[precio_prom_semanal.is_new == \"new\"]\n",
    "productos_usados = precio_prom_semanal[precio_prom_semanal.is_new == \"used\"]\n",
    "\n",
    "# Create traces\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=productos_nuevos[\"date_created\"], y=productos_nuevos[\"price\"],\n",
    "                    mode='lines',\n",
    "                    name='nuevos'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=productos_usados[\"date_created\"], y=productos_usados[\"price\"],\n",
    "                    mode='lines',\n",
    "                    name='usados'))\n",
    "\n",
    "#fig.add_trace(go.Scatter(x=df_grouped[\"FECHA_VENTA\"], y=df_grouped[\"TICKET_PROMEDIO\"],\n",
    "#                    mode='lines',\n",
    "#                    name='TICKET_PROMEDIO'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text= \"PRECIO PROMEDIO SEMANAL\", # title of plot\n",
    "    xaxis_tickfont_size=8,\n",
    "    xaxis_title_text='FECHA', # xaxis label\n",
    "    yaxis_title_text='PRECIO', # yaxis label\n",
    "\n",
    ") \n",
    "\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c6e301",
   "metadata": {},
   "outputs": [],
   "source": [
    "#precio promedio por categoria de productos nuevos y usados\n",
    "precio_by_category = df_train.groupby([\"is_new\",\"category_id\"]).price.mean().reset_index()\n",
    "#precio_by_category.pivot_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9550279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "precio_by_category.is_new.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df6a46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "precio_cat = pd.pivot_table(precio_by_category, values='price',index=['category_id'], columns=['is_new'])\n",
    "precio_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7d48b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "precio_cat[(precio_cat.new.notnull()) & (precio_cat.used.notnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b40701d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"category_id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a80f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hipotesis\n",
    "#la descripcion debiese reflejar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e59bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101557c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260f4e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una instancia del vectorizador Bag of Words\n",
    "stop_words_es = get_stop_words('spanish')\n",
    "vectorizer = CountVectorizer(stop_words=stop_words_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55a4048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar stemming a los vectores numéricos\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "X_train_stemmed = [[stemmer.stem(word) for word in nltk.word_tokenize(document)] for document in X_train]\n",
    "X_test_stemmed = [[stemmer.stem(word) for word in nltk.word_tokenize(document)] for document in X_test]\n",
    "\n",
    "# Volver a transformar los datos en vectores numéricos después del stemming\n",
    "X_train_vectorized = vectorizer.fit_transform([' '.join(doc) for doc in X_train_stemmed])\n",
    "X_test_vectorized = vectorizer.transform([' '.join(doc) for doc in X_test_stemmed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd2ea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar las descripciones en vectores numéricos\n",
    "\n",
    "# Agregar la variable cantidad_disponible al conjunto de características vectorizadas\n",
    "\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train[\"descripcion_combinada\"])\n",
    "X_test_vectorized = vectorizer.transform(X_test[\"descripcion_combinada\"])\n",
    "\n",
    "\n",
    "#from scipy.sparse import hstack\n",
    "#X_train_vectorized = hstack((X_train_vectorized, X_train['available_quantity'].values.reshape(-1, 1)))\n",
    "#X_test_vectorized = hstack((X_test_vectorized, X_test['available_quantity'].values.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed38653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar las categorías utilizando la codificación one-hot\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "categories_encoded_train = encoder.fit_transform(X_train[\"category_id\"].values.reshape(-1, 1))\n",
    "categories_encoded_test = encoder.transform(X_test[\"category_id\"].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e474c8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectorized = hstack((X_train_vectorized, categories_encoded_train))\n",
    "X_test_vectorized = hstack((X_test_vectorized, categories_encoded_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92dda31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear y entrenar el modelo de clasificación (Naive Bayes)\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = classifier.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluar el rendimiento del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Precisión del modelo: {accuracy:.2f}')\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print('Informe de clasificación:')\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d24c918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar la matriz de confusión\n",
    "#conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "#print('Matriz de Confusión:')\n",
    "#print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1857231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame({\"y\":y_test_raw, \"y_pred\": y_pred})\n",
    "conf_matrix = pd.crosstab(out.y, out.y_pred, rownames=['Etiqueta Real'], colnames=['Predicción'], margins=True)\n",
    "print('Matriz de Confusión:')\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0724b12a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcb8b96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
